{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ddfbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahil\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np\n",
    "\n",
    "# Create a face recognizer using OpenCV\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Create lists to store face images and labels\n",
    "faces_data = []\n",
    "labels_list = []\n",
    "\n",
    "# Create a dictionary to store label and associated name\n",
    "labels_dict = {0: \"Sahil\", 1: \"Sanskruti\", 2: \"Rutuja\"}\n",
    "\n",
    "# Load the MTCNN face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Iterate through each person's images for training\n",
    "for p_id in range(1, 4):\n",
    "    for i_id in range(1, 4):\n",
    "        img_path = f'C:\\\\Users\\\\sahil\\\\JupyterNotebook\\\\Machine learning\\\\OpenCVtutorial\\\\Face Recognition\\\\dataset\\\\person{p_id}\\\\img{i_id}.jpg'\n",
    "        \n",
    "        # Read the image in grayscale\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Check if the image is loaded successfully\n",
    "        if img is None:\n",
    "            print(f\"Error: Could not read image {img_path}\")\n",
    "            continue\n",
    "\n",
    "        # Resize the image to a common size (e.g., 100x100)\n",
    "        common_size = (500, 500)\n",
    "        img = cv2.resize(img, common_size)\n",
    "        \n",
    "        # Store the face image and its corresponding label in the lists\n",
    "        faces_data.append(img)\n",
    "        labels_list.append(p_id - 1)\n",
    "\n",
    "# Convert the labels to the required format (CV_32SC1)\n",
    "labels_array = np.array(labels_list, dtype=np.int32)\n",
    "\n",
    "# Train the recognizer with the collected faces data and labels\n",
    "recognizer.train(faces_data, labels_array)\n",
    "\n",
    "# Save the trained recognizer to a file\n",
    "recognizer.save('face_recognizer2.yml')\n",
    "\n",
    "# Now, you can use the trained model in your main code for face recognition\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c96e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image recognizer\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('face_recognizer2.yml')\n",
    "\n",
    "# Load an image for face recognition\n",
    "image_path = \"C:\\\\Users\\\\sahil\\\\JupyterNotebook\\\\Machine learning\\\\OpenCVtutorial\\\\Face Recognition\\\\Dataset\\\\sample.jpg\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "# image = cv2.resize(image,(1200,800))\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detector = MTCNN()\n",
    "# Detect faces in the image\n",
    "faces = detector.detect_faces(image)\n",
    "\n",
    "# Perform face recognition on each detected face\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    face_roi = gray_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Perform face recognition\n",
    "    label, confidence = recognizer.predict(face_roi)\n",
    "\n",
    "    # Map the label to the corresponding name\n",
    "    person_name = labels_dict.get(label, \"Unknown\")\n",
    "\n",
    "    if confidence < 100:\n",
    "        print(f\"Detected {person_name} with confidence {confidence}\")\n",
    "    else:\n",
    "        print(\"Unknown face\")\n",
    "\n",
    "    # Draw a rectangle around the detected face\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with rectangles around detected faces\n",
    "cv2.imshow(\"Detected Faces\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('face_recognizer2.yml')\n",
    "\n",
    "# Load the face detector from OpenCV\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open a connection to the webcam (usually index 0, but you might need to adjust)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "faces_data = []\n",
    "labels_list = []\n",
    "\n",
    "# Create a dictionary to store label and associated name\n",
    "labels_dict = {0: \"Sahil\", 1: \"Sanskruti\", 2: \"Rutuja\"}\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "#     Convert the frame to grayscale for face detection\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face region\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Perform face recognition\n",
    "        label, confidence = recognizer.predict(face_roi)\n",
    "\n",
    "        # If the confidence is below a certain threshold, consider it a match\n",
    "        if confidence < 100:\n",
    "            person_name = labels_dict[label]\n",
    "            cv2.putText(frame, f\"{person_name} ({confidence:.2f}%)\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Unknown\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c2c605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahil\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person1\\img1.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person1\\img2.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person1\\img3.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person2\\img1.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person2\\img2.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person2\\img3.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person3\\img1.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person3\\img2.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person3\\img3.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person4\\img1.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person4\\img2.jpg\n",
      "Reading image from: C:\\Users\\sahil\\JupyterNotebook\\Machine learning\\OpenCVtutorial\\Face Recognition\\Dataset\\person4\\img3.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = MTCNN()\n",
    "\n",
    "faces = []\n",
    "label = []\n",
    "label_dict = {0:\"sahil\",1:\"sans\",2:\"rut\",3:\"vaishnavi\"}\n",
    "\n",
    "for pid in range(1,5):\n",
    "    for iid in range(1,4):\n",
    "        path = f\"C:\\\\Users\\\\sahil\\\\JupyterNotebook\\\\Machine learning\\\\OpenCVtutorial\\\\Face Recognition\\\\Dataset\\\\person{pid}\\\\img{iid}.jpg\"\n",
    "        print(f\"Reading image from: {path}\")\n",
    "\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Failed to read image from path: {path}\")\n",
    "        else:\n",
    "            common_size = (100, 100)\n",
    "            image = cv2.resize(image, common_size)\n",
    "            faces.append(image)\n",
    "            label.append(pid - 1)\n",
    "\n",
    "label_array = np.array(label,dtype = np.int32)\n",
    "\n",
    "recognizer.train(faces,label_array)\n",
    "\n",
    "recognizer.save(\"dataset3.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea5410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "vaishnavi with a confidence of 85.24483028426717\n"
     ]
    }
   ],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"dataset3.yml\")\n",
    "detector = MTCNN()\n",
    "\n",
    "path = \"C:\\\\Users\\\\sahil\\\\JupyterNotebook\\\\Machine learning\\\\OpenCVtutorial\\\\Face Recognition\\\\Dataset\\\\sample.jpg\"\n",
    "image = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "resize = cv2.resize(image,(500,500))\n",
    "\n",
    "faces = detector.detect_faces(resize)\n",
    "\n",
    "for face in faces:\n",
    "    x,y,w,h = face[\"box\"]\n",
    "    face = image[y:y+h,x:x+w]\n",
    "    face = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    label,confidence = recognizer.predict(face)\n",
    "    pname = label_dict.get(label,\"unknown\")\n",
    "\n",
    "    if confidence <= 100:\n",
    "        print(f\"{pname} with a confidence of {confidence}\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"unknown\")\n",
    "\n",
    "r = cv2.rectangle(resize, (x,y), (x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "cv2.imshow(\"image\", r)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcceb723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face-recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting dlib>=19.7\n",
      "  Using cached dlib-19.24.2-cp310-cp310-win_amd64.whl\n",
      "Collecting face-recognition-models>=0.3.0\n",
      "  Using cached face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from face-recognition) (9.4.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from face-recognition) (8.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from face-recognition) (1.23.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from Click>=6.0->face-recognition) (0.4.6)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py): started\n",
      "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=7b8c40d99b7fe3768c0a54f11349a293bd19cf3930d1a40e7a357b471fd396b3\n",
      "  Stored in directory: c:\\users\\sahil\\appdata\\local\\pip\\cache\\wheels\\3a\\81\\70\\bb23245d63de9e0f53fc67dc6f30d871d443521aa026808210\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models, dlib, face-recognition\n",
      "Successfully installed dlib-19.24.2 face-recognition-1.3.0 face-recognition-models-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb16a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi im and face authenticator and Vaishnavi's face is recognized and the result is [True]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "vaishnavi = face_recognition.load_image_file(\"dataset/person4/img1.jpg\")\n",
    "unknown_image = face_recognition.load_image_file(\"dataset/person4/img2.jpg\")\n",
    "\n",
    "vaishnavi_encoding = face_recognition.face_encodings(vaishnavi)[0]\n",
    "unknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([vaishnavi_encoding], unknown_encoding)\n",
    "print(f\"Hi im and face authenticator and Vaishnavi's face is recognized and the result is {results}\")\n",
    "\n",
    "# image = cv2.imread(\"dataset/person4/img1.jpg\")\n",
    "image1 = cv2.imread(\"dataset/person4/img3.jpg\")\n",
    "# resize = cv2.resize(image,(500,500))\n",
    "resize1 = cv2.resize(image1,(500,500))\n",
    "# Display the image\n",
    "# cv2.imshow('Image', resize)\n",
    "cv2.imshow('Image', resize1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db09d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
